{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARL ASSI 1: Question 1\n",
    "\n",
    "Ananya Gandhi (20319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovDecisionProcess:\n",
    "    def __init__(self, states: List[str], actions: List[str], \n",
    "                 transition_probs: Dict[str, Dict[str, List[Tuple[str, float]]]], \n",
    "                 rewards: Dict[str, float], discount_factor: float):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.transition_probs = transition_probs\n",
    "        self.rewards = rewards\n",
    "        self.discount_factor = discount_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    def __init__(self, mdp: MarkovDecisionProcess, threshold: float = 1e-5):\n",
    "        self.mdp = mdp\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def run(self) -> Tuple[Dict[str, float], Dict[str, str]]:\n",
    "        V = {state: 0 for state in self.mdp.states}\n",
    "        policy = {state: None for state in self.mdp.states}\n",
    "\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in self.mdp.states:\n",
    "                old_v = V[state]\n",
    "                V[state], policy[state] = self._get_max_action_value(state, V)\n",
    "                delta = max(delta, abs(old_v - V[state]))\n",
    "            \n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "\n",
    "        return V, policy\n",
    "\n",
    "    def _get_max_action_value(self, state: str, V: Dict[str, float]) -> Tuple[float, str]:\n",
    "        return max(\n",
    "            (self._calculate_action_value(state, action, V), action)\n",
    "            for action in self.mdp.actions\n",
    "        )\n",
    "\n",
    "    def _calculate_action_value(self, state: str, action: str, V: Dict[str, float]) -> float:\n",
    "        return self.mdp.rewards[state] + self.mdp.discount_factor * sum(\n",
    "            prob * V[next_state]\n",
    "            for next_state, prob in self.mdp.transition_probs[state].get(action, [])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIteration:\n",
    "    def __init__(self, mdp: MarkovDecisionProcess, threshold: float = 1e-5):\n",
    "        self.mdp = mdp\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def run(self) -> Dict[str, str]:\n",
    "        policy = {state: np.random.choice(self.mdp.actions) for state in self.mdp.states}\n",
    "\n",
    "        while True:\n",
    "            V = self._policy_evaluation(policy)\n",
    "            if self._policy_improvement(policy, V):\n",
    "                break\n",
    "\n",
    "        return policy\n",
    "\n",
    "    def _policy_evaluation(self, policy: Dict[str, str]) -> Dict[str, float]:\n",
    "        V = {state: 0 for state in self.mdp.states}\n",
    "        \n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in self.mdp.states:\n",
    "                old_v = V[state]\n",
    "                action = policy[state]\n",
    "                V[state] = self._calculate_state_value(state, action, V)\n",
    "                delta = max(delta, abs(old_v - V[state]))\n",
    "            \n",
    "            if delta < self.threshold:\n",
    "                break\n",
    "\n",
    "        return V\n",
    "\n",
    "    def _policy_improvement(self, policy: Dict[str, str], V: Dict[str, float]) -> bool:\n",
    "        policy_stable = True\n",
    "        \n",
    "        for state in self.mdp.states:\n",
    "            old_action = policy[state]\n",
    "            policy[state] = max(\n",
    "                self.mdp.actions,\n",
    "                key=lambda a: self._calculate_action_value(state, a, V)\n",
    "            )\n",
    "            if old_action != policy[state]:\n",
    "                policy_stable = False\n",
    "        \n",
    "        return policy_stable\n",
    "\n",
    "    def _calculate_state_value(self, state: str, action: str, V: Dict[str, float]) -> float:\n",
    "        return self.mdp.rewards[state] + self.mdp.discount_factor * sum(\n",
    "            prob * V[next_state]\n",
    "            for next_state, prob in self.mdp.transition_probs[state].get(action, [])\n",
    "        )\n",
    "\n",
    "    def _calculate_action_value(self, state: str, action: str, V: Dict[str, float]) -> float:\n",
    "        return self.mdp.rewards[state] + self.mdp.discount_factor * sum(\n",
    "            prob * V[next_state]\n",
    "            for next_state, prob in self.mdp.transition_probs[state].get(action, [])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Hostel\", \"Academic_Building\", \"Canteen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"Class\", \"Eat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    \"Hostel\": {\n",
    "        \"Class\": [(\"Hostel\", 0.5), (\"Academic_Building\", 0.5)],\n",
    "        \"Eat\": [(\"Canteen\", 1.0)]\n",
    "    },\n",
    "    \"Academic_Building\": {\n",
    "        \"Class\": [(\"Academic_Building\", 0.7), (\"Canteen\", 0.3)],\n",
    "        \"Eat\": [(\"Canteen\", 0.8), (\"Academic_Building\", 0.2)]\n",
    "    },\n",
    "    \"Canteen\": {\n",
    "        \"Class\": [(\"Academic_Building\", 0.6), (\"Hostel\", 0.3), (\"Canteen\", 0.1)],\n",
    "        \"Eat\": [(\"Canteen\", 1.0)]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = {\n",
    "    \"Hostel\": -1,\n",
    "    \"Academic_Building\": 3,\n",
    "    \"Canteen\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = MarkovDecisionProcess(states, actions, transition_probs, rewards, discount_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Values from Value Iteration: {'Hostel': 16.05617127561447, 'Academic_Building': 21.846450338494776, 'Canteen': 18.826646891106996}\n",
      "Optimal Policy from Value Iteration: {'Hostel': 'Class', 'Academic_Building': 'Class', 'Canteen': 'Class'}\n"
     ]
    }
   ],
   "source": [
    "# Run Value Iteration\n",
    "vi = ValueIteration(mdp)\n",
    "optimal_values, optimal_policy_value_iteration = vi.run()\n",
    "print(\"Optimal Values from Value Iteration:\", optimal_values)\n",
    "print(\"Optimal Policy from Value Iteration:\", optimal_policy_value_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy from Policy Iteration: {'Hostel': 'Class', 'Academic_Building': 'Class', 'Canteen': 'Class'}\n"
     ]
    }
   ],
   "source": [
    "# Run Policy Iteration\n",
    "pi = PolicyIteration(mdp)\n",
    "optimal_policy_policy_iteration = pi.run()\n",
    "print(\"Optimal Policy from Policy Iteration:\", optimal_policy_policy_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
